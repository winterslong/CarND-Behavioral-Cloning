{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "simu_data_path = './data'\n",
    "\n",
    "train_mode = \"nVidia\"\n",
    "save_model_file = 'model_nv_optdata_e2.h5'\n",
    "nepochs = 2\n",
    "\n",
    "#train_mode = \"LeNet\" \n",
    "#save_model_file = 'model_lenet_optdata_e2.h5'\n",
    "#nepochs = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getLinesFromDrivingLogs(dataPath, skipHeader=False):\n",
    "    \"\"\"\n",
    "    Returns the lines from a driving log with base directory `dataPath`.\n",
    "    If the file include headers, pass `skipHeader=True`.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    driving_log_file = dataPath + '/driving_log.csv'\n",
    "    with open(driving_log_file) as csvFile:\n",
    "        reader = csv.reader(csvFile)\n",
    "        if skipHeader:\n",
    "            next(reader, None)\n",
    "        for line in reader:\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "\n",
    "def findImages(dataPath):\n",
    "    \"\"\"\n",
    "    Finds all the images needed for training on the path `dataPath`.\n",
    "    Returns `([centerPaths], [leftPath], [rightPath], [steering])`\n",
    "    \"\"\"\n",
    "    directories = [x[0] for x in os.walk(dataPath)]\n",
    "    dataDirectories = list(filter(lambda directory: os.path.isfile(directory + '/driving_log.csv'), directories))\n",
    "    dataDirectories.sort()\n",
    "    \n",
    "    centerTotal = []\n",
    "    leftTotal = []\n",
    "    rightTotal = []\n",
    "    steeringTotal = [] \n",
    "    for directory in dataDirectories:\n",
    "        lines = getLinesFromDrivingLogs(directory, True)\n",
    "        center = []\n",
    "        left = []\n",
    "        right = []\n",
    "        steering = []\n",
    "        for line in lines:\n",
    "            steering.append(float(line[3]))\n",
    "            center.append(directory + '/' + line[0].strip())\n",
    "            left.append(directory + '/' + line[1].strip())\n",
    "            right.append(directory + '/' + line[2].strip())\n",
    "            \n",
    "        centerTotal.extend(center)\n",
    "        leftTotal.extend(left)\n",
    "        rightTotal.extend(right)\n",
    "        steeringTotal.extend(steering)\n",
    "        print(\"directory=\", directory)\n",
    "        print(\"    center=\", len(center))\n",
    "        print(\"    left  =\", len(left))\n",
    "        print(\"    right =\", len(right))\n",
    "        print(\"    steerings =\", len(steering))\n",
    "    return (centerTotal, leftTotal, rightTotal, steeringTotal)\n",
    "\n",
    "def extendImages(center, left, right, steering, correction):\n",
    "    \"\"\"\n",
    "    Extend the image paths from `center`, `left` and `right` using the correction factor `correction`\n",
    "    Returns ([imagePaths], [steerings])\n",
    "    \"\"\"\n",
    "    imagePaths = []\n",
    "    imagePaths.extend(center)\n",
    "    imagePaths.extend(left)\n",
    "    imagePaths.extend(right)\n",
    "    \n",
    "    steerings = []\n",
    "    steerings.extend(steering)\n",
    "    steerings.extend([x + correction for x in steering])\n",
    "    steerings.extend([x - correction for x in steering])\n",
    "    return (imagePaths, steerings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory= ./data\\data\n",
      "    center= 8036\n",
      "    left  = 8036\n",
      "    right = 8036\n",
      "    steerings = 8036\n",
      "Total:\n",
      "centerPaths : 8036\n",
      "leftPaths   : 8036\n",
      "rightPaths  : 8036\n",
      "steerings   : 8036\n",
      "\n",
      "Total Images   : 24108\n",
      "Total steerings: 24108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Reading images locations.\n",
    "centerPaths, leftPaths, rightPaths, steerings = findImages(simu_data_path)\n",
    "print('Total:')\n",
    "print('centerPaths : {}'.format( len(centerPaths)))\n",
    "print('leftPaths   : {}'.format( len(leftPaths)))\n",
    "print('rightPaths  : {}'.format( len(rightPaths)))\n",
    "print('steerings   : {}'.format( len(steerings)))\n",
    "print()\n",
    "\n",
    "imagePaths, steerings = extendImages(centerPaths, leftPaths, rightPaths, steerings, 0.2)\n",
    "print('Total Images   : {}'.format( len(imagePaths)))\n",
    "print('Total steerings: {}'.format( len(steerings)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate the required images and measurments for training/\n",
    "    `samples` is a list of pairs (`imagePath`, `steering`).\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        samples = sklearn.utils.shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for imagePath, steering in batch_samples:\n",
    "                originalImage = cv2.imread(imagePath)\n",
    "                image = cv2.cvtColor(originalImage, cv2.COLOR_BGR2RGB)\n",
    "                images.append(image)\n",
    "                angles.append(steering)\n",
    "                # Flipping\n",
    "                images.append(cv2.flip(image,1))\n",
    "                angles.append(steering*-1.0)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            inputs = np.array(images)\n",
    "            outputs = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(inputs, outputs)\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Lambda, Convolution2D, Cropping2D, Conv2D\n",
    "from keras.layers import Dropout, Activation\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def createPreProcessingLayers():\n",
    "    \"\"\"\n",
    "    Creates a model with the initial pre-processing layers.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "    return model\n",
    "\n",
    "def nVidiaModel():\n",
    "    \"\"\"    Creates nVidea Autonomous Car Group model   \"\"\"\n",
    "    print(\"######### In nVidia Model ######### \")\n",
    "    model = createPreProcessingLayers()     \n",
    "    model.add(Convolution2D(24,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(48,5,5, subsample=(2,2), activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Convolution2D(64,3,3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def LeNet():\n",
    "    print(\"######### In LeNet Model #########\")\n",
    "    model = createPreProcessingLayers()\n",
    "    model.add(Conv2D(6, (5, 5),activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(6, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D())    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120))    \n",
    "    model.add(Dense(84))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))    \n",
    "    model.summary()    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 19286\n",
      "Validation samples: 4822\n",
      "######### In nVidia Model ######### \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               844900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 981,819\n",
      "Trainable params: 981,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winterslong\\AppData\\Local\\conda\\conda\\envs\\wlong-gpu-tf-py36\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "C:\\Users\\winterslong\\AppData\\Local\\conda\\conda\\envs\\wlong-gpu-tf-py36\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "C:\\Users\\winterslong\\AppData\\Local\\conda\\conda\\envs\\wlong-gpu-tf-py36\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "C:\\Users\\winterslong\\AppData\\Local\\conda\\conda\\envs\\wlong-gpu-tf-py36\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\winterslong\\AppData\\Local\\conda\\conda\\envs\\wlong-gpu-tf-py36\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "C:\\Users\\winterslong\\AppData\\Local\\conda\\conda\\envs\\wlong-gpu-tf-py36\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\winterslong\\AppData\\Local\\conda\\conda\\envs\\wlong-gpu-tf-py36\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., verbose=1, steps_per_epoch=19286, epochs=2, validation_steps=4822)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting train_data and creating generators.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = list(zip(imagePaths, steerings))\n",
    "X_train, X_validation = train_test_split(train_data, test_size=0.2)\n",
    "print('Train samples: {}'.format(len(X_train)))\n",
    "print('Validation samples: {}'.format(len(X_validation)))\n",
    "\n",
    "#\"\"\"\n",
    "train_generator = generator(X_train, batch_size=32)\n",
    "validation_generator = generator(X_validation, batch_size=32)\n",
    "\n",
    "# Model creation\n",
    "if (train_mode == \"LeNet\"):\n",
    "    model = LeNet()\n",
    "else:  #\"nVidia\"\n",
    "    model = nVidiaModel()\n",
    "    \n",
    "# Compiling and training the model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history_object = model.fit_generator(train_generator, \n",
    "                        samples_per_epoch= len(X_train), \n",
    "                        validation_data=validation_generator, \n",
    "                        nb_val_samples=len(X_validation), \n",
    "                        nb_epoch=nepochs, \n",
    "                        verbose=1)\n",
    "\n",
    "model.save(save_model_file)\n",
    "#model.save('model_lenet.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(history_object.history.keys())\n",
    "print('Loss')\n",
    "print(history_object.history['loss'])\n",
    "print('Validation Loss')\n",
    "print(history_object.history['val_loss'])\n",
    "#\"\"\"\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "#\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python wlong-gpu-tf-py36",
   "language": "python",
   "name": "wlong-gpu-tf-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
